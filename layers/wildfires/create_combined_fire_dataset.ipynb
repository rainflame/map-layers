{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b98a9a-af25-400a-806f-b97f03ae191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import jellyfish\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from shapely.geometry.polygon import orient\n",
    "from shapely.geometry import shape, Point\n",
    "from shapely.ops import unary_union\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "import fiona\n",
    "\n",
    "from alive_progress import alive_bar\n",
    "import geopy.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca93ba-33bf-4b55-971d-715f68c4347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shapefile(file_path):\n",
    "    with fiona.open(file_path, 'r') as shp:\n",
    "        # read the features and handle broken geometries\n",
    "        features = []\n",
    "        with alive_bar(len(shp), title=\"Loading shapefile...\", force_tty=True) as bar:\n",
    "            for feature in shp:\n",
    "                try:\n",
    "                    # create a valid feature by fixing the geometry\n",
    "                    valid_feature = {'geometry': shape(feature['geometry']).buffer(\n",
    "                        0), 'properties': feature['properties']}\n",
    "                    features.append(valid_feature)\n",
    "                except Exception as e:\n",
    "                    print(\"Error fixing geometry, skipping feature\")\n",
    "                bar()\n",
    "\n",
    "    gdf = gpd.GeoDataFrame.from_features(features)\n",
    "    gdf.crs = shp.crs\n",
    "    # only keep polygons\n",
    "    gdf = gdf[gdf.geometry.type != 'Point']\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d63ce-805e-43b0-b696-1d95790c9bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_causes(df): \n",
    "\n",
    "    # remap usfs cause codes to their corresponding causes\n",
    "    usfs_cause_map = {\n",
    "        '1': 'lightning',\n",
    "        '2': 'equipment',\n",
    "        '3': 'smoking',\n",
    "        '4': 'campfire',\n",
    "        '5': 'debris burning',\n",
    "        '6': 'railroad',\n",
    "        '7': 'arson',\n",
    "        '8': 'children',\n",
    "        '9': 'miscellaneous',\n",
    "    }\n",
    "\n",
    "    for num, cause in usfs_cause_map.items():\n",
    "        df.loc[df['CAUSE_2'] == num, 'CAUSE_2'] = cause\n",
    "\n",
    "    # remap layer 2 causes to a standardized set of cases\n",
    "    layer_2_cause_map = {\n",
    "        None: None,\n",
    "        'campfire': 'camping',\n",
    "        'equipment': 'equipment and vehicle use',\n",
    "        'children': 'misuse of fire by a minor',\n",
    "        '5-debris burning': 'debris and open burning',\n",
    "        'debris/open burning': 'debris and open burning',\n",
    "        'debris burning': 'debris and open burning',\n",
    "        'railroad': 'railroad operations and maintenance',\n",
    "        'firearms and explosives use': 'firearms and weapons',\n",
    "        'firearms/weapons': 'firearms and weapons',\n",
    "        'power generation/transmission/distribution': 'utilities',\n",
    "        'incindiary':'incendiary',\n",
    "        '7-arson': 'arson',\n",
    "        'undetermined': None,\n",
    "        'miscellaneous': None,\n",
    "        'undetermined (remarks required)': None,\n",
    "        'cause and origin not identified': None,\n",
    "        'investigated but undetermined': None,\n",
    "        'investigated but und': None,\n",
    "        'cause not identified': None,\n",
    "        'undetermined (remar*': None,\n",
    "        '9 - miscellaneous': None,\n",
    "        '10': None,\n",
    "        '14': None,\n",
    "        '0': None\n",
    "    }\n",
    "\n",
    "    for og_cause, cause in layer_2_cause_map.items():\n",
    "        df.loc[df['CAUSE_2'] == og_cause, 'CAUSE_2'] = cause\n",
    "        \n",
    "    # existing layer 2 causes common in both datasets \n",
    "    # 'incendiary'\n",
    "    # 'lightning'\n",
    "    # 'camping'\n",
    "    # 'recreation and ceremony'\n",
    "    # 'other human cause'\n",
    "    # 'other natural cause'\n",
    "    # 'arson'\n",
    "    # 'coal seam'\n",
    "    # 'smoking'\n",
    "    # 'utilities'\n",
    "\n",
    "    # generate layer 1 causes from layer 2 causes\n",
    "    layer_1_cause_map = {\n",
    "        'human': 'human',\n",
    "        'natural': 'natural',\n",
    "        None: None,\n",
    "        'equipment and vehicle use': 'human',\n",
    "        'misuse of fire by a minor': 'human',\n",
    "        'debris and open burning': 'human',\n",
    "        'railroad operations and maintenance': 'human',\n",
    "        'firearms and weapons': 'human',\n",
    "        'incendiary': 'human',\n",
    "        'camping': 'human',\n",
    "        'recreation and ceremony': 'human',\n",
    "        'arson': 'human',\n",
    "        'smoking': 'human',\n",
    "        'utilities':'human',\n",
    "        'other human cause': 'human',\n",
    "        'coal seam': 'human',\n",
    "        'lightning': 'natural',\n",
    "        'other natural cause': 'natural',\n",
    "        'volcanic': 'natural',\n",
    "        'undetermined': None\n",
    "    }\n",
    "\n",
    "    def create_layer_1_value(row):\n",
    "        if pd.isnull(row['CAUSE_1']):\n",
    "            try:    \n",
    "                return layer_1_cause_map[row['CAUSE_2']]\n",
    "            except KeyError as e:\n",
    "                return None\n",
    "        return row['CAUSE_1']\n",
    "\n",
    "    df['CAUSE_1'] = df.apply(create_layer_1_value, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118bd565-c08c-4c1d-85f2-f252a34a3cda",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load USFS fire dataset.\n",
    "usfs_path = \"data/sources/USFSPerimeters/*.shp\"\n",
    "if len(glob.glob(usfs_path)) == 0:\n",
    "    raise Exception(\"No USFS shapefile found at path {}\".format(usfs_path))\n",
    "else:\n",
    "    usfs_df = load_shapefile(\n",
    "        glob.glob(usfs_path)[0])\n",
    "\n",
    "\n",
    "usfs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09011b72-afbf-4058-b18b-dbdaaed248ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only the columns of interest.\n",
    "\n",
    "# https://data.fs.usda.gov/geodata/edw/edw_resources/meta/S_USA.FinalFirePerimeter.xml\n",
    "usfs_remap = {\n",
    "    'FIRENAME': 'NAME',\n",
    "    'FIREYEAR': 'YEAR',\n",
    "    'OWNERAGENC': 'AGENCY',\n",
    "    'STATCAUSE': 'CAUSE_2',\n",
    "    'DISCOVERYD': 'STARTDATE',\n",
    "    'geometry': 'geometry',\n",
    "}\n",
    "usfs_df_sel = usfs_df.rename(columns=usfs_remap)\n",
    "usfs_df_sel = usfs_df_sel[list(usfs_remap.values())]\n",
    "usfs_df_sel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6119c-857d-4eae-8d44-17e99c026a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the USFS dataset.\n",
    "\n",
    "# no endtime in this dataset, but add the column anyway\n",
    "usfs_df_st = usfs_df_sel.copy()\n",
    "usfs_df_st['ENDDATE'] = None\n",
    "usfs_df_st['SOURCE'] = 'USFS'\n",
    "\n",
    "\n",
    "# drop rows where year is null\n",
    "usfs_df_st = usfs_df_st.dropna(subset=['YEAR'])\n",
    "\n",
    "# convert year to datetime\n",
    "usfs_df_st['YEAR'] = usfs_df_st['YEAR'].astype(int).astype(str)\n",
    "\n",
    "# clean up name values\n",
    "usfs_df_st['NAME'] = usfs_df_st['NAME'].str.lower()\n",
    "usfs_df_st['NAME'].fillna('unnamed fire', inplace=True)\n",
    "usfs_df_st['NAME'] = usfs_df_st['NAME'].replace('unnamed', 'unnamed fire')\n",
    "usfs_df_st['NAME'] = usfs_df_st['NAME'].replace('noname', 'unnamed fire')\n",
    "usfs_df_st['NAME'] = usfs_df_st['NAME'].replace('unknown', 'unnamed fire')\n",
    "usfs_df_st['NAME'] = usfs_df_st['NAME'].replace('missing', 'unnamed fire')\n",
    "usfs_df_st['NAME'] = usfs_df_st['NAME'].replace('n/a', 'unnamed fire')\n",
    "\n",
    "# clean up cause values \n",
    "usfs_df_st['CAUSE_2'] = usfs_df_st['CAUSE_2'].str.lower()\n",
    "usfs_df_st['CAUSE_1'] = None\n",
    "usfs_df_st['CAUSE_3'] = None\n",
    "\n",
    "usfs_df_st = standardize_causes(usfs_df_st)\n",
    "    \n",
    "usfs_df_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f55da-f52d-40aa-82c9-94afcdc5caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BLM fire dataset.\n",
    "blm_path = \"data/sources/BLMPerimeters/*.shp\"\n",
    "if len(glob.glob(blm_path)) == 0:\n",
    "    raise Exception(\"No BLM shapefile found at path {}\".format(blm_path))\n",
    "else:\n",
    "    blm_df = load_shapefile(\n",
    "        glob.glob(blm_path)[0])\n",
    "\n",
    "blm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def9d92-0260-41e3-90c9-c37323e96af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns of interest.\n",
    "\n",
    "# https://gbp-blm-egis.hub.arcgis.com/datasets/BLM-EGIS::blm-natl-fire-perimeters-polygon/about\n",
    "blm_remap = {\n",
    "    'INCDNT_NM': 'NAME',\n",
    "    'FIRE_DSCVR': 'YEAR',\n",
    "    'FIRE_CAUSE': 'CAUSE_1',\n",
    "    'FIRE_DSC_1': 'STARTDATE',\n",
    "    'FIRE_CNTRL': 'ENDDATE',\n",
    "    'geometry': 'geometry',\n",
    "}\n",
    "blm_df_sel = blm_df.rename(columns=blm_remap)\n",
    "blm_df_sel = blm_df_sel[list(blm_remap.values())]\n",
    "blm_df_sel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7501eb-b891-4b05-b935-c56be412fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the BLM dataset.\n",
    "\n",
    "blm_df_st = blm_df_sel.copy()\n",
    "blm_df_st['SOURCE'] = 'BLM'\n",
    "\n",
    "# drop rows where year is null\n",
    "blm_df_st = blm_df_st.dropna(subset=['YEAR'])\n",
    "\n",
    "# convert year to datetime\n",
    "blm_df_st['YEAR'] = blm_df_st['YEAR'].astype(int).astype(str)\n",
    "\n",
    "# clean up name values\n",
    "blm_df_st['NAME'] = blm_df_st['NAME'].str.lower()\n",
    "blm_df_st['NAME'].fillna('unnamed fire', inplace=True)\n",
    "blm_df_st['NAME'] = blm_df_st['NAME'].replace('not available', 'unnamed fire')\n",
    "blm_df_st['NAME'] = blm_df_st['NAME'].replace('unnamed', 'unnamed fire')\n",
    "blm_df_st['NAME'] = blm_df_st['NAME'].replace('unknown', 'unnamed fire')\n",
    "\n",
    "# standardize causes\n",
    "blm_df_st['CAUSE_1'] = blm_df_st['CAUSE_1'].str.lower()\n",
    "blm_df_st['CAUSE_1'] = blm_df_st['CAUSE_1'].replace('uk', None)\n",
    "blm_df_st['CAUSE_1'] = blm_df_st['CAUSE_1'].replace('unknown', None)\n",
    "blm_df_st['CAUSE_1'].fillna('undetermined', inplace=True)\n",
    "blm_df_st['CAUSE_2'] = None\n",
    "blm_df_st['CAUSE_3'] = None\n",
    "\n",
    "blm_df_st['ENDDATE'] = blm_df_st['ENDDATE'].replace('9999-09-09', None)\n",
    "    \n",
    "blm_df_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3407c-53e4-4ba8-b4c4-92a41aec3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NIFC fire dataset.\n",
    "nifc_path = \"data/sources/NIFCPerimeters/*.shp\"\n",
    "if len(glob.glob(nifc_path)) == 0:\n",
    "    raise Exception(\"No NIFC shapefile found at path {}\".format(nifc_path))\n",
    "else:\n",
    "    nifc_df = load_shapefile(\n",
    "        glob.glob(nifc_path)[0])\n",
    "\n",
    "nifc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7665b91-b87b-4c07-8c8a-5d3b28a81b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nifc_df[nifc_df[\"poly_Incid\"] == \"Holiday Farm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d3fe7-c0ea-4715-b164-1ef59417bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns of interest.\n",
    "\n",
    "# https://data-nifc.opendata.arcgis.com/datasets/nifc::wfigs-interagency-fire-perimeters/about\n",
    "nifc_remap = {\n",
    "    'poly_Incid': 'NAME',\n",
    "    # XXX: 'YEAR', # will need to calculate this from STARTDATE\n",
    "    'attr_FireC': 'CAUSE_1',\n",
    "    'attr_Fir_4': 'CAUSE_2',\n",
    "    'attr_Fir_5': 'CAUSE_3',\n",
    "    'attr_POOLa': 'AGENCY',\n",
    "    'attr_Fir_7': 'STARTDATE', \n",
    "    'attr_Conta': 'ENDDATE',\n",
    "    'geometry': 'geometry',\n",
    "}\n",
    "nifc_df_sel = nifc_df.rename(columns=nifc_remap)\n",
    "nifc_df_sel = nifc_df_sel[list(nifc_remap.values())]\n",
    "nifc_df_sel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76f1c6-7dc1-4833-81f9-da5768fc0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the NIFC dataset.\n",
    "\n",
    "nifc_df_st = nifc_df_sel.copy()\n",
    "\n",
    "# compute year from STARTDATE\n",
    "nifc_df_st['YEAR'] = [e[:4] for e in nifc_df_st['STARTDATE']]\n",
    "\n",
    "nifc_df_st['SOURCE'] = 'NIFC'\n",
    "\n",
    "# clean up name values\n",
    "nifc_df_st['NAME'] = nifc_df_st['NAME'].str.lower()\n",
    "nifc_df_st['NAME'].fillna('unnamed fire', inplace=True)\n",
    "blm_df_st['NAME'] = blm_df_st['NAME'].replace('unnamed', 'unnamed fire')\n",
    "nifc_df_st['NAME'] = nifc_df_st['NAME'].replace('noname', 'unnamed fire')\n",
    "nifc_df_st['NAME'] = nifc_df_st['NAME'].replace('unknown', 'unnamed fire')\n",
    "nifc_df_st['NAME'] = nifc_df_st['NAME'].replace('missing', 'unnamed fire')\n",
    "nifc_df_st['NAME'] = nifc_df_st['NAME'].replace('n/a', 'unnamed fire')\n",
    "\n",
    "# clean up cause values \n",
    "nifc_df_st['CAUSE_1'] = nifc_df_st['CAUSE_1'].str.lower()\n",
    "nifc_df_st['CAUSE_2'] = nifc_df_st['CAUSE_2'].str.lower()\n",
    "nifc_df_st['CAUSE_3'] = nifc_df_st['CAUSE_3'].str.lower()\n",
    "\n",
    "nifc_df_st = standardize_causes(nifc_df_st)\n",
    "    \n",
    "nifc_df_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4621d7ae-6d9b-41c6-916f-c1ca4ab73932",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fires_df = pd.concat([usfs_df_st, blm_df_st, nifc_df_st])\n",
    "\n",
    "# remove old fires\n",
    "all_fires_df = all_fires_df[all_fires_df['STARTDATE'] >= '1900-01-01']\n",
    "\n",
    "all_fires_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233684e4-492d-4cf9-9bdf-7c83f613607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the centroids of each fire polygon.\n",
    "all_fires_df['CENTROID'] = all_fires_df.geometry.centroid.apply(Point)\n",
    "all_fires_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e496974-0e57-4f77-9554-f16fde01ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the area of each fire polygon (m^2).\n",
    "\n",
    "# https://gis.stackexchange.com/questions/413349/calculating-area-of-lat-lon-polygons-without-transformation-using-geopandas\n",
    "def gpd_geographic_area(geodf):\n",
    "    if not (geodf.crs and geodf.crs.is_geographic):\n",
    "        raise TypeError('geodataframe should have geographic coordinate system')\n",
    "\n",
    "    with alive_bar(len(geodf.index), title=\"Calculating geometry areas...\", force_tty=True) as bar:\n",
    "        geod = geodf.crs.get_geod()\n",
    "        def area_calc(geom, skip_bar=False):\n",
    "            if geom.geom_type not in ['MultiPolygon','Polygon']:\n",
    "                return np.nan\n",
    "            \n",
    "            # For MultiPolygon do each separately\n",
    "            if geom.geom_type=='MultiPolygon':\n",
    "                r =  np.sum([area_calc(p, True) for p in geom.geoms])\n",
    "                bar()\n",
    "                return r\n",
    "            else:\n",
    "                # orient to ensure a counter-clockwise traversal. \n",
    "                # See https://pyproj4.github.io/pyproj/stable/api/geod.html\n",
    "                # geometry_area_perimeter returns (area, perimeter)\n",
    "                r =  geod.geometry_area_perimeter(orient(geom, 1))[0]\n",
    "                if not skip_bar:\n",
    "                    bar()\n",
    "                return r\n",
    "                \n",
    "        return geodf.geometry.apply(area_calc)\n",
    "\n",
    "all_fires_df.set_crs(\"EPSG:4326\", inplace=True)\n",
    "all_fires_df['AREA'] = gpd_geographic_area(all_fires_df)\n",
    "all_fires_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95c043-c706-4280-9d3e-f933098ac9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df ready to export as a shapefile.\n",
    "# out_df = all_fires_df.copy()\n",
    "\n",
    "# # export to shapefile does not handle GeometryDtype\n",
    "# out_df = out_df.drop(columns=['CENTROID'])\n",
    "\n",
    "# # set projection so can properly save geometry\n",
    "# out_df.set_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "# print(out_df.head())\n",
    "\n",
    "# # Convert dataframe to shapefile to analyze in QGIS.\n",
    "# out_df.to_file(\"data/all_fire_groups.shp\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e632b25-0e09-455a-9950-546a26fa23e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the difference in area must be no more than 20%\n",
    "AREA_THRESHOLD = 0.2\n",
    "DISTANCE_THRESHOLD = 1500\n",
    "\n",
    "def get_area_diff(area_r1_m2, area_r2_m2):\n",
    "    # percent difference between the two areas \n",
    "    return abs(area_r1_m2 - area_r2_m2) / ((area_r1_m2 + area_r2_m2) / 2)\n",
    "\n",
    "areas = []\n",
    "distances = []\n",
    "intersections = []\n",
    "diff = []\n",
    "\n",
    "def same_geom_heuristic(r1, r2):\n",
    "\n",
    "    n1 = r1['NAME']\n",
    "    n2 = r2['NAME']\n",
    "\n",
    "    if n2 == n2 or jellyfish.jaro_winkler_similarity(n1, n2) < 0.5:\n",
    "        # check that the two have a similar size \n",
    "        percent_diff = get_area_diff(r1['AREA'], r2['AREA'])\n",
    "        if percent_diff < AREA_THRESHOLD:\n",
    "            # now check that their centroids are an allowable distance apart \n",
    "            c1 = r1['CENTROID']\n",
    "            c2 = r2['CENTROID']\n",
    "            dist = geopy.distance.geodesic((c1.y, c1.x), (c2.y, c2.x))\n",
    "    \n",
    "            if dist.meters <= DISTANCE_THRESHOLD:\n",
    "    \n",
    "                g1 = gpd.GeoSeries(r1['geometry'])\n",
    "                g2 = gpd.GeoSeries(r2['geometry'])\n",
    "                intersects = g1.intersects(g2).any()\n",
    "    \n",
    "                areas.append(r1['AREA'])\n",
    "                distances.append(dist.meters)\n",
    "                intersections.append(intersects)\n",
    "                diff.append(percent_diff)\n",
    "                \n",
    "                return intersects\n",
    "                \n",
    "    return False\n",
    "\n",
    "# def same_geom_heuristic(r1, r2):\n",
    "#     dist_ok = same_centroid_heuristic(r1, r2)\n",
    "#     if dist_ok:\n",
    "#         g1 = gpd.GeoSeries(r1['geometry'])\n",
    "#         g2 = gpd.GeoSeries(r2['geometry'])\n",
    "#         s = g1.geom_almost_equals(g2, decimal=1)\n",
    "#         return s.all()\n",
    "#     return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec129c-94b8-47b0-813a-6f97fd431003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find groups of rows that likely represent the same fire.\n",
    "def find_fire_groups_same_names(df):\n",
    "    groups = df.groupby(['NAME', 'YEAR'])\n",
    "    \n",
    "    with alive_bar(groups.ngroups, title=\"Grouping similar fires, pass 1...\", force_tty=True) as bar:\n",
    "        fire_groups_list = []\n",
    "        for name, group in groups: \n",
    "            n = len(group.index)\n",
    "            colors = np.arange(n)\n",
    "        \n",
    "            # color rows by first row that is transitively close to it\n",
    "            for i in range(n):\n",
    "                for j in range(i+1, n):\n",
    "                    if same_geom_heuristic(group.iloc[i], group.iloc[j]): colors[j] = colors[i]\n",
    "        \n",
    "            group['COLOR'] = colors\n",
    "            cgroups = group.groupby(['COLOR'])\n",
    "            fire_groups_list += [cgroup for _, cgroup in cgroups]\n",
    "    \n",
    "            bar()\n",
    "    \n",
    "    fire_df = pd.concat(fire_groups_list)\n",
    "    fire_groups = fire_df.groupby(['NAME', 'YEAR', 'COLOR'])\n",
    "    return fire_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3465cba-0ae9-406f-a142-5b19f2ec8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fire_groups_different_names(df):\n",
    "    groups = df.groupby(['YEAR'])\n",
    "\n",
    "    with alive_bar(groups.ngroups, title=\"Grouping similar fires, pass 2...\", force_tty=True) as bar:\n",
    "        fire_groups_list = []\n",
    "        for name, group in groups:\n",
    "            n = len(group.index)\n",
    "            colors = np.arange(n)\n",
    "\n",
    "            # color rows by first row that is transitively close to it\n",
    "            for i in range(n):\n",
    "                for j in range(i+1, n):\n",
    "                    if same_geom_heuristic(group.iloc[i], group.iloc[j]):\n",
    "                        colors[j] = colors[i]\n",
    "\n",
    "            group['COLOR'] = colors\n",
    "            cgroups = group.groupby(['COLOR'])\n",
    "            fire_groups_list += [cgroup for _, cgroup in cgroups]\n",
    "\n",
    "            bar()\n",
    "\n",
    "    fire_df = pd.concat(fire_groups_list)\n",
    "    fire_groups = fire_df.groupby(['YEAR', 'COLOR'])\n",
    "    return fire_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6580dac0-fea4-4b48-97a0-c2e55057ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupError(Exception):\n",
    "    pass\n",
    "    \n",
    "def analyze_combine_group(group):\n",
    "    # Prefer rows given this particular ordering of sources.\n",
    "    source_rows = {}\n",
    "    for index, row in group.iterrows():\n",
    "        source = row['SOURCE']\n",
    "        if source not in source_rows:\n",
    "            source_rows[source] = []\n",
    "        source_rows[source].append(row)\n",
    "    ref_rows_by_source = []\n",
    "    for source in ['NIFC', 'USFS', 'BLM']:\n",
    "        if source in source_rows:\n",
    "            ref_rows_by_source = source_rows[source]\n",
    "            break\n",
    "    if len(ref_rows_by_source) == 0:\n",
    "        raise GroupError(\"No rows for group by source\")\n",
    "\n",
    "    # Prefer rows with a more specific cause.\n",
    "    cause_specificity = {1: [], 2: [], 3: []}\n",
    "    for row in ref_rows_by_source:\n",
    "        if row['CAUSE_3']:\n",
    "            cause_specificity[3].append(row)\n",
    "        elif row['CAUSE_2']:\n",
    "            cause_specificity[2].append(row)\n",
    "        else:\n",
    "            cause_specificity[1].append(row)\n",
    "    ref_rows_by_pref = []\n",
    "    for preference in [3, 2, 1]:\n",
    "        if len(cause_specificity[preference]) > 0:\n",
    "            ref_rows_by_pref = cause_specificity[preference]\n",
    "            break\n",
    "    if len(ref_rows_by_pref) == 0:\n",
    "        raise GroupError(\"No rows for group by cause specificity\")\n",
    "\n",
    "    ref_rows = ref_rows_by_pref\n",
    "\n",
    "    # Identify and report conflicts in ref_rows.\n",
    "    conflicts = []\n",
    "        \n",
    "    agencies = set([e['AGENCY'] for e in ref_rows])\n",
    "    if len(agencies) > 1: conflicts.append(\"More than 1 agency: {}\".format(agencies))\n",
    "\n",
    "    cause1 = set([e['CAUSE_1'] for e in ref_rows])\n",
    "    cause1_f = [e for e in cause1 if e != \"undetermined\"]\n",
    "    if len(cause1_f) > 1: conflicts.append(\"More than one 1st-order cause: {}\".format(cause1_f))\n",
    "\n",
    "    cause2 = set([e['CAUSE_2'] for e in ref_rows])\n",
    "    if len(cause2) > 1: conflicts.append(\"More than one 2nd-order cause: {}\".format(cause2))\n",
    "\n",
    "    cause3 = set([e['CAUSE_3'] for e in ref_rows])\n",
    "    if len(cause3) > 1: conflicts.append(\"More than one 3rd-order cause: {}\".format(cause3))\n",
    "\n",
    "    start = set([e['STARTDATE'] for e in ref_rows if e['STARTDATE']])\n",
    "    start_f = [e for e in start]\n",
    "    if len(start_f) > 1: conflicts.append(\"More than one startdate: {}\".format(start_f))\n",
    "\n",
    "    end = set([e['ENDDATE'] for e in ref_rows if e['ENDDATE']])\n",
    "    end_f = set([e for e in end])\n",
    "    if len(end_f) > 1: conflicts.append(\"More than one enddate: {}\".format(end_f))\n",
    "\n",
    "    geos = [e['geometry'] for e in ref_rows]\n",
    "    multiple = False\n",
    "    for i in range(len(geos)):\n",
    "        geo1 = geos[i]\n",
    "        for j in range(i+1, len(geos)):\n",
    "            geo2 = geos[j]\n",
    "            if not geo1.equals_exact(geo2, 1e-6):\n",
    "                multiple = True\n",
    "                break\n",
    "            if multiple:\n",
    "                break\n",
    "    if multiple:\n",
    "        conflicts.append(\"More than one geometry\")\n",
    "\n",
    "    #if len(ref_rows) > 1:\n",
    "    #    if len(conflicts) > 0:\n",
    "    #        for conflict in conflicts:\n",
    "    #            print(conflict)\n",
    "    #        print()\n",
    "\n",
    "    # Somewhat arbitrarily choose the last entry.\n",
    "    # This is deterministic assuming rows maintain order throughout all previous operations.\n",
    "    final_row = ref_rows[-1]\n",
    "    return final_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf086ac-a659-449d-b9b6-afa9c146162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass 1 combination \n",
    "fire_groups_pass1 = find_fire_groups_same_names(all_fires_df)\n",
    "\n",
    "fires_list_pass1 = []\n",
    "for _, group in fire_groups_pass1:\n",
    "    try:\n",
    "        row = analyze_combine_group(group)\n",
    "    except GroupError as e:\n",
    "        print(\"ERROR: {}\".format(e))\n",
    "        continue\n",
    "    fires_list_pass1.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc82758-5d75-44c2-8217-f83a8fa51c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_analysis_df = pd.DataFrame(list(zip(areas, distances, intersections, diff)), columns=[\"area\", \"distance\", \"intersects\", \"difference\"])\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "g = sns.scatterplot(x=\"area\", y=\"distance\", hue=\"intersects\", data=dist_analysis_df, color=\"b\").set(title=\"Fires with the same name and year\", xlabel=\"polygon area (m^2)\", ylabel=\"distance between polygon centroids (m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b0eb6-076e-4516-b1fe-1210ed561129",
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_df_pass1 = gpd.GeoDataFrame(fires_list_pass1)\n",
    "print(\"Pass 1 dedupped from {} to {} rows\".format(len(all_fires_df.index), len(fires_df_pass1.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5333e-e62f-4b5b-a5e0-02c19caa10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass 2 combination \n",
    "fire_groups_pass2 = find_fire_groups_different_names(fires_df_pass1)\n",
    "\n",
    "fires_list_pass2 = []\n",
    "for _, group in fire_groups_pass2:\n",
    "    try:\n",
    "        row = analyze_combine_group(group)\n",
    "    except GroupError as e:\n",
    "        print(\"ERROR: {}\".format(e))\n",
    "        continue\n",
    "    fires_list_pass2.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc486b-89a9-46ce-be19-fbf1634a041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_analysis_df = pd.DataFrame(list(zip(areas, distances, intersections, diff)), columns=[\"area\", \"distance\", \"intersects\", \"difference\"])\n",
    "\n",
    "g = sns.scatterplot(x=\"area\", y=\"distance\", hue=\"intersects\", data=dist_analysis_df, color=\"b\").set(title=\"Fires with the same year\", xlabel=\"polygon area (m^2)\", ylabel=\"distance between polygon centroids (m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed957d7-6c9f-4ec3-8ab1-717baa6d218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_df_pass2 = gpd.GeoDataFrame(fires_list_pass2)\n",
    "print(\"Pass 2 dedupped from {} to {} rows\".format(len(fires_df_pass1.index), len(fires_df_pass2.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463932f-fa19-4cd0-94d4-9d3d174e83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df ready to export as a shapefile.\n",
    "\n",
    "out_df = fires_df_pass2.copy()\n",
    "\n",
    "# final cleanup, convert area to acres\n",
    "out_df['AREA'] = out_df['AREA'] * 0.0002471054\n",
    "out_df['YEAR'] = out_df['YEAR'].astype(int)\n",
    "\n",
    "\n",
    "# export to shapefile does not handle GeometryDtype\n",
    "out_df = out_df.drop(columns=['CENTROID'])\n",
    "\n",
    "# set projection so can properly save geometry\n",
    "out_df.set_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "# Convert dataframe to shapefile to analyze in QGIS.\n",
    "out_df.to_file(\"data/fires.shp\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b0e50-59b9-4e3c-b416-0ec1814d386c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
