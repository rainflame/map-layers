{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests \n",
    "import urllib3\n",
    "from alive_progress import alive_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting next page of items to 50\n",
      "requesting next page of items to 100\n",
      "requesting next page of items to 150\n",
      "requesting next page of items to 200\n",
      "requesting next page of items to 250\n",
      "requesting next page of items to 300\n",
      "requesting next page of items to 350\n",
      "requesting next page of items to 400\n",
      "requesting next page of items to 450\n",
      "requesting next page of items to 500\n",
      "requesting next page of items to 550\n",
      "requesting next page of items to 600\n",
      "requesting next page of items to 650\n",
      "requesting next page of items to 700\n",
      "requesting next page of items to 750\n",
      "requesting next page of items to 800\n",
      "requesting next page of items to 850\n",
      "requesting next page of items to 900\n",
      "requesting next page of items to 950\n",
      "requesting next page of items to 1000\n",
      "requesting next page of items to 1050\n",
      "requesting next page of items to 1100\n",
      "requesting next page of items to 1150\n",
      "requesting next page of items to 1200\n",
      "requesting next page of items to 1250\n",
      "requesting next page of items to 1300\n",
      "requesting next page of items to 1350\n",
      "requesting next page of items to 1400\n",
      "requesting next page of items to 1450\n",
      "requesting next page of items to 1500\n",
      "requesting next page of items to 1550\n",
      "requesting next page of items to 1600\n",
      "requesting next page of items to 1650\n",
      "requesting next page of items to 1700\n",
      "requesting next page of items to 1750\n",
      "requesting next page of items to 1800\n",
      "requesting next page of items to 1850\n",
      "requesting next page of items to 1900\n",
      "requesting next page of items to 1950\n",
      "requesting next page of items to 2000\n",
      "requesting next page of items to 2050\n",
      "requesting next page of items to 2100\n",
      "requesting next page of items to 2150\n",
      "requesting next page of items to 2200\n",
      "requesting next page of items to 2250\n",
      "requesting next page of items to 2300\n",
      "requesting next page of items to 2350\n",
      "requesting next page of items to 2400\n",
      "requesting next page of items to 2450\n",
      "requesting next page of items to 2500\n",
      "requesting next page of items to 2550\n",
      "requesting next page of items to 2600\n",
      "Total download size: 78.18 GB\n"
     ]
    }
   ],
   "source": [
    "# using the 1 arc-second dataset, but could use 1/3 arc-second for higher resolution\n",
    "dataset= \"National Elevation Dataset (NED) 1 arc-second\"\n",
    "\n",
    "# set the bounding box for the region we want to download DEMs for\n",
    "us_continental_bbox = \"-125.0011,24.9493,-66.9326,49.5904\"\n",
    "us_west_bbox = \"-100.336147,50.059513,-127.850165,29.983312\"\n",
    "oregon_bbox = \"-124.566244,46.864746,-116.463504,41.991794\"\n",
    "\n",
    "# USGS national map api endpoint to list DEMs for our bounding box\n",
    "url = \"https://tnmaccess.nationalmap.gov/api/v1/products?datasets={}&bbox={}\".format(dataset, us_continental_bbox)\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "urls = []\n",
    "download_bytes = 0\n",
    "\n",
    "total_items = data['total']\n",
    "n = len(data['items'])\n",
    "\n",
    "while n < total_items:\n",
    "    print(\"requesting next page of items to {}\".format(n))\n",
    "    url += '&offset=' + str(n)\n",
    "    response = requests.get(url + \"&offset={}\".format(n))\n",
    "    data = response.json()\n",
    "    for item in data['items']:\n",
    "        urls.append(item['downloadURL'])\n",
    "        download_bytes += item['sizeInBytes']\n",
    "\n",
    "    n += len(data['items'])\n",
    "\n",
    "\n",
    "print('Total download size: {:.2f} GB'.format(download_bytes / 1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping downloading 0 files that already exist\n",
      "Downloading data... |████████████████████████████████████████| 65/65 [100%] in 4\n"
     ]
    }
   ],
   "source": [
    "# create data/sources/ dir if it doesn't already exist\n",
    "if not os.path.exists('data/sources'):\n",
    "    os.makedirs('data/sources')\n",
    "\n",
    "# filter out any urls that already exist as saved files\n",
    "filtered_urls = [url for url in urls if not os.path.exists(os.path.join('data/sources', url.split('/')[-1]))]\n",
    "\n",
    "print(\"Skipping downloading {} files that already exist\".format(len(urls) - len(filtered_urls)))\n",
    "\n",
    "def request(method, url):\n",
    "    try:\n",
    "        r = urllib3.request(method, url)\n",
    "        return r\n",
    "    except Exception as e:\n",
    "        print('Failed to download', url, e)\n",
    "        return None\n",
    "    \n",
    "# download the data and save each file to data/sources/\n",
    "with alive_bar(len(filtered_urls), title=\"Downloading data...\", force_tty=True) as bar:\n",
    "    for url in filtered_urls:\n",
    "        filename = url.split('/')[-1]\n",
    "        try:\n",
    "            filepath = os.path.join('data/sources', filename)\n",
    "            if not os.path.exists(filepath):\n",
    "                data = request(\"GET\", url)\n",
    "                # save the data to filepath\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    f.write(data.data)\n",
    "        except Exception as e:\n",
    "            print('Failed to download', filename, e)\n",
    "        bar()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
